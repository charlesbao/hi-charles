<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>HTTP代理扫描工具 | Hi!Charles</title>
<meta name="keywords" content="作品, Python, 脚本">
<meta name="description" content="
用Python实现的http代理扫描工具，利用爬虫抓取代理网站，并存储到数据库永久储存。
">
<meta name="author" content="">
<link rel="canonical" href="/post/http_scan/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="HTTP代理扫描工具" />
<meta property="og:description" content="
用Python实现的http代理扫描工具，利用爬虫抓取代理网站，并存储到数据库永久储存。
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/http_scan/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-06-02T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-06-02T00:00:00+00:00" /><meta property="og:site_name" content="Hi!Charles" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="HTTP代理扫描工具"/>
<meta name="twitter:description" content="
用Python实现的http代理扫描工具，利用爬虫抓取代理网站，并存储到数据库永久储存。
"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "/post/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "HTTP代理扫描工具",
      "item": "/post/http_scan/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "HTTP代理扫描工具",
  "name": "HTTP代理扫描工具",
  "description": " 用Python实现的http代理扫描工具，利用爬虫抓取代理网站，并存储到数据库永久储存。\n",
  "keywords": [
    "作品", "Python", "脚本"
  ],
  "articleBody": " 用Python实现的http代理扫描工具，利用爬虫抓取代理网站，并存储到数据库永久储存。\n数据库使用 sqlite3\n依赖\npip install requesocks bs4\n# encoding=utf8 from multiprocessing.dummy import Pool as ThreadPool from bs4 import BeautifulSoup import requesocks as requests import datetime import json import time import sqlite3 import re import os def recordProxy(ip, port, country, valid = 0, req_speed = None, proxies = None): checkDate = time.strftime('%Y-%m-%d %H:%M:%S') executeScript = \"SELECT IP from PROXY WHERE IP = '%s'\" \\ % ip cursor = conn.executescript(executeScript) if valid == 0: # 检查是否有重复 for _ in cursor: executeScript = \"UPDATE PROXY set VALID = 0, CHECK_DATE = '%s' where IP='%s'\" \\ % (checkDate,ip) conn.executescript(executeScript) return False # 插入一条无效连接代理IP executeScript = \"INSERT INTO PROXY (IP,PORT,COUNTRY,CHECK_DATE,VALID) VALUES ('%s', %d, '%s', '%s', 0)\" \\ % (ip, port, country,checkDate) conn.executescript(executeScript) else: # 检查是否有重复 for _ in cursor: executeScript = \"UPDATE PROXY set REQ_SPEED='%f', PROXIES='%s', VALID = 1, CHECK_DATE = '%s' where IP='%s'\" \\ % (req_speed,proxies,checkDate, ip) conn.executescript(executeScript) return True executeScript = \"INSERT INTO PROXY (IP,PORT,COUNTRY,REQ_SPEED,PROXIES,CHECK_DATE,VALID) VALUES ('%s', %d, '%s', '%f', '%s', '%s', 1)\" \\ % (ip, port, country,req_speed,proxies,checkDate) conn.executescript(executeScript) def checkProxy(ProxyValue): (ip,port,country) = ProxyValue for proxySuffix in ['http','https']: try: startTime = datetime.datetime.now() session.proxies = {'http': '%s://%s:%d' % (proxySuffix,ip,port)} resHeaders = session.get('http://www.baidu.com/img/baidu_jgylogo3.gif', timeout=3).headers except: continue else: if resHeaders['content-length'] == '705': endTime = datetime.datetime.now() req_speed = round(float((endTime - startTime).microseconds) / 1000000, 4) # 插入一条有效连接代理IP print ip, proxySuffix, req_speed recordProxy(ip, port, country, valid=1,req_speed=req_speed,proxies=proxySuffix) return True print ip,'error' # 插入一条无效连接代理IP recordProxy(ip,port,country,valid=0) return False def scanProxy(ProxyArr): pool = ThreadPool(5) pool.map(checkProxy, ProxyArr) pool.close() pool.join() def getCountry(ip): try: # 获取ip所在地 contents = requests.get('http://int.dpool.sina.com.cn/iplookup/iplookup.php?format=json\u0026ip=%s' % ip).content except: print 'network:country api error' os._exit(1) else: try: jsonObj = json.loads(contents) except: print 'jsonLoad:country api error' os._exit(1) else: if 'country' in contents: return jsonObj['country'] else: print 'hasNoCountryID:country api error' os._exit(1) def getProxy(): for page in range(1,250): try: # 需要扫描的网址 contents = requests.get('http://www.xicidaili.com/wn/%d' % page,headers = header, timeout = 5).content except: print 'proxyError' else: soup = BeautifulSoup(contents, \"html.parser\") ProxyArr = [] if len(soup.select('tr')) == 1: print 'page',page,'end' os._exit(0) for tr in soup.select('tr'): td = tr.select('td') if len(td) \u003e 3: ip = td[1].text if not re.search('.+\\..+\\..+\\..+',ip,re.S) is None: try: port = int(td[2].text) except: print td[2].text os._exit(1) else: country = getCountry(ip) ProxyArr.append((ip,port,country)) print 'begin scan', len(ProxyArr) #begin to check proxy validity scanProxy(ProxyArr) header = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36' } session = requests.session() session.headers.update(header) # 数据库设计 # ID IP PORT COUNTRY PROXIES REQ_SPEED CHECK_DATE VALID # int text int text text float text int # 32 8 32 8 8 64 2 # 数据库地址 conn = sqlite3.connect('/Users/chalresbao/Documents/proxy.db',check_same_thread=False) getProxy() conn.close() ",
  "wordCount" : "412",
  "inLanguage": "en",
  "datePublished": "2022-06-02T00:00:00Z",
  "dateModified": "2022-06-02T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/http_scan/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Hi!Charles",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="Hi!Charles (Alt + H)">Hi!Charles</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      HTTP代理扫描工具
    </h1>
    <div class="post-meta"><span title='2022-06-02 00:00:00 +0000 UTC'>June 2, 2022</span>

</div>
  </header> 
  <div class="post-content"><blockquote>
<p>用Python实现的http代理扫描工具，利用爬虫抓取代理网站，并存储到数据库永久储存。</p>
</blockquote>
<p>数据库使用 sqlite3<br>
依赖<br>
pip install requesocks bs4</p>
<pre tabindex="0"><code># encoding=utf8
from multiprocessing.dummy import Pool as ThreadPool
from bs4 import BeautifulSoup

import requesocks as requests
import datetime
import json
import time
import sqlite3
import re
import os

def recordProxy(ip, port, country, valid = 0, req_speed = None, proxies = None):

    checkDate = time.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)
    executeScript = &#34;SELECT IP from PROXY WHERE IP = &#39;%s&#39;&#34; \
                    % ip
    cursor = conn.executescript(executeScript)
    if valid == 0:
        # 检查是否有重复
        for _ in cursor:
            executeScript = &#34;UPDATE PROXY set VALID = 0, CHECK_DATE = &#39;%s&#39; where IP=&#39;%s&#39;&#34; \
                            % (checkDate,ip)
            conn.executescript(executeScript)
            return False
        # 插入一条无效连接代理IP
        executeScript = &#34;INSERT INTO PROXY (IP,PORT,COUNTRY,CHECK_DATE,VALID) VALUES (&#39;%s&#39;, %d, &#39;%s&#39;, &#39;%s&#39;, 0)&#34; \
                        % (ip, port, country,checkDate)
        conn.executescript(executeScript)
    else:
        # 检查是否有重复
        for _ in cursor:
            executeScript = &#34;UPDATE PROXY set REQ_SPEED=&#39;%f&#39;, PROXIES=&#39;%s&#39;, VALID = 1, CHECK_DATE = &#39;%s&#39; where IP=&#39;%s&#39;&#34; \
                            % (req_speed,proxies,checkDate, ip)
            conn.executescript(executeScript)
            return True
        executeScript = &#34;INSERT INTO PROXY (IP,PORT,COUNTRY,REQ_SPEED,PROXIES,CHECK_DATE,VALID) VALUES (&#39;%s&#39;, %d, &#39;%s&#39;, &#39;%f&#39;, &#39;%s&#39;, &#39;%s&#39;, 1)&#34;  \
                        % (ip, port, country,req_speed,proxies,checkDate)
        conn.executescript(executeScript)

def checkProxy(ProxyValue):

    (ip,port,country) = ProxyValue

    for proxySuffix in [&#39;http&#39;,&#39;https&#39;]:
        try:
            startTime = datetime.datetime.now()
            session.proxies = {&#39;http&#39;: &#39;%s://%s:%d&#39; % (proxySuffix,ip,port)}
            resHeaders = session.get(&#39;http://www.baidu.com/img/baidu_jgylogo3.gif&#39;, timeout=3).headers
        except:
            continue
        else:
            if resHeaders[&#39;content-length&#39;] == &#39;705&#39;:
                endTime = datetime.datetime.now()
                req_speed = round(float((endTime - startTime).microseconds) / 1000000, 4)
                # 插入一条有效连接代理IP
                print ip, proxySuffix, req_speed
                recordProxy(ip, port, country, valid=1,req_speed=req_speed,proxies=proxySuffix)
                return True
    print ip,&#39;error&#39;
    # 插入一条无效连接代理IP
    recordProxy(ip,port,country,valid=0)
    return False

def scanProxy(ProxyArr):
    pool = ThreadPool(5)
    pool.map(checkProxy, ProxyArr)
    pool.close()
    pool.join()

def getCountry(ip):

    try:
        # 获取ip所在地
        contents = requests.get(&#39;http://int.dpool.sina.com.cn/iplookup/iplookup.php?format=json&amp;ip=%s&#39; % ip).content
    except:
        print &#39;network:country api error&#39;
        os._exit(1)
    else:
        try:
            jsonObj = json.loads(contents)
        except:
            print &#39;jsonLoad:country api error&#39;
            os._exit(1)
        else:
            if &#39;country&#39; in contents:
                return jsonObj[&#39;country&#39;]
            else:
                print &#39;hasNoCountryID:country api error&#39;
                os._exit(1)

def getProxy():

    for page in range(1,250):
        try:
            # 需要扫描的网址
            contents = requests.get(&#39;http://www.xicidaili.com/wn/%d&#39; % page,headers = header, timeout = 5).content
        except:
            print &#39;proxyError&#39;
        else:
            soup = BeautifulSoup(contents, &#34;html.parser&#34;)
            ProxyArr = []
            if len(soup.select(&#39;tr&#39;)) == 1:
                print &#39;page&#39;,page,&#39;end&#39;
                os._exit(0)
            for tr in soup.select(&#39;tr&#39;):
                td = tr.select(&#39;td&#39;)
                if len(td) &gt; 3:
                    ip = td[1].text
                    if not re.search(&#39;.+\..+\..+\..+&#39;,ip,re.S) is None:
                        try:
                            port = int(td[2].text)
                        except:
                            print td[2].text
                            os._exit(1)
                        else:
                            country = getCountry(ip)
                            ProxyArr.append((ip,port,country))

            print &#39;begin scan&#39;, len(ProxyArr)
            #begin to check proxy validity
            scanProxy(ProxyArr)

header = {
    &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.80 Safari/537.36&#39;
}
session = requests.session()
session.headers.update(header)

# 数据库设计
# ID    IP      PORT    COUNTRY     PROXIES     REQ_SPEED   CHECK_DATE  VALID
# int   text    int     text        text        float       text        int
#       32      8       32          8           8           64          2

# 数据库地址
conn = sqlite3.connect(&#39;/Users/chalresbao/Documents/proxy.db&#39;,check_same_thread=False)
getProxy()
conn.close()
</code></pre>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="/tags/%E4%BD%9C%E5%93%81/">作品</a></li>
      <li><a href="/tags/python/">Python</a></li>
      <li><a href="/tags/%E8%84%9A%E6%9C%AC/">脚本</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <section class="copyright"><a href="https://beian.miit.gov.cn">苏ICP备16024813号-3</a> | <a href="/">"Hi!Charles"为包涵个人的版权所有</a></section>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
